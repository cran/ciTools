<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Matthew Avery" />

<meta name="date" content="2017-10-11" />

<title>Binomial Regression with ciTools</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Binomial Regression with <code>ciTools</code></h1>
<h4 class="author"><em>Matthew Avery</em></h4>
<h4 class="date"><em>11 October 2017</em></h4>



<div id="logistic-regression-with-binomial-data" class="section level2">
<h2>Logistic regression with binomial data</h2>
<p>Logistic regression is most commonly used with a Bernoulli response. If <span class="math inline">\(Y \sim Bernoulli(p)\)</span>, then <span class="math inline">\(P(Y = 1) = p = 1 - P(Y = 0)\)</span>. Logistic regression can be used to estimate <span class="math inline">\(p|\textbf{x}\)</span> where <span class="math inline">\(\textbf{x}\)</span> is a collection of predictor variables. This is accomplished by assuming the relationship</p>
<p><span class="math display">\[log(\frac{p}{1-p}) = \textbf{x}\beta\]</span></p>
<p>and then choosing <span class="math inline">\(\beta\)</span> to maximize the joint likelihood:</p>
<p><span class="math display">\[\Pi_i p_i^{y_i}(1-p_i)^{(1-y_i)}\]</span></p>
<p>Note that the function linking the predictor variables to <span class="math inline">\(p\)</span> is called the logit function, which is what gives logistic regression its name. In <span class="math inline">\(\textbf{R}\)</span>, this model can be fit using <code>glm</code> by specifying the options <code>family = &quot;binomial&quot;</code>.</p>
<p>The binomial distribution is a generalization of the Bernoulli, typically conceptualized as describing the number of “successes” (here denoted <span class="math inline">\(y\)</span>) out of some number of attempts or trials (here denoted <span class="math inline">\(n\)</span>). The probability mass function for a binomial random variable, <span class="math inline">\(Y\)</span>, is</p>
<p><span class="math display">\[P(Y = y|n, p) = {x \choose n} p^x(1 - p)^{n - x}\]</span></p>
<p>From this, we can see that by setting <span class="math inline">\(n = 1\)</span>, we recover the Bernoulli PMF.</p>
<p>Since the binomial distribution is a generalization of the Bernoulli distribution, it stands to reason that it may be possible to generalize logistic regression for Bernoulli variables to binomial variables. Indeed, this is the case, and it turns out it is relatively easy. Using the logit link function again, maximize the joint likelihood:</p>
<p><span class="math display">\[\Pi_i {y_i \choose n_i} p_i^{y_i}(1-p_i)^{(1-y_i)}\]</span></p>
</div>
<div id="binomial-regression-in-r" class="section level2">
<h2>Binomial regression in R</h2>
<p>R is also capable of fitting binomial regression models using <code>glm</code> with <code>family = &quot;binomial&quot;</code>. However, there are a few syntactic quirks. First, in the model statement, the response variable must be given as a proportion of successes for a given run. This can be done either by providing the proportions as a column in the data matrix or by specifying a ratio of the number of successes to the number of attempts. An example here might be instructive.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">20171011</span>)
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(ciTools)
<span class="kw">library</span>(broom)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tb &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">x =</span> <span class="kw">runif</span>(<span class="dv">30</span>, <span class="dv">-1</span>, <span class="dv">1</span>),
  <span class="dt">n =</span> <span class="kw">rbinom</span>(<span class="dv">30</span>, <span class="dv">6</span>, <span class="fl">.8</span>)
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">rbinom</span>(<span class="dv">30</span>, n, (<span class="kw">exp</span>(x)<span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(x)))))</code></pre></div>
<p>Consider the data set, <code>tb</code>, given below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tb</code></pre></div>
<pre><code>## # A tibble: 30 x 3
##              x     n     y
##          &lt;dbl&gt; &lt;int&gt; &lt;int&gt;
##  1 -0.01132681     5     1
##  2 -0.26414193     4     2
##  3 -0.81380816     4     0
##  4  0.55575400     4     3
##  5  0.65899013     6     3
##  6  0.89954037     4     3
##  7 -0.90649045     6     0
##  8  0.04080467     5     1
##  9 -0.87067950     4     3
## 10 -0.84626183     4     1
## # ... with 20 more rows</code></pre>
<p>Here, <span class="math inline">\(x\)</span> is some predictor variable related to the number of successes, <span class="math inline">\(y\)</span>, for the given number of attempts, <span class="math inline">\(n\)</span>. We can fit a logistic regression to this data to estimate this relationship:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glm</span>(y<span class="op">/</span>n <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> tb, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">weights =</span> n) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</code></pre></div>
<pre><code>##          term  estimate std.error statistic     p.value
## 1 (Intercept) 0.1040801 0.1767316 0.5889159 0.555917662
## 2           x 0.9449956 0.3159439 2.9910234 0.002780442</code></pre>
<p>We get the same results using different syntax:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tbProb &lt;-<span class="st"> </span><span class="kw">mutate</span>(tb, <span class="dt">prob =</span> y<span class="op">/</span>n)
tbProb</code></pre></div>
<pre><code>## # A tibble: 30 x 4
##              x     n     y  prob
##          &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
##  1 -0.01132681     5     1  0.20
##  2 -0.26414193     4     2  0.50
##  3 -0.81380816     4     0  0.00
##  4  0.55575400     4     3  0.75
##  5  0.65899013     6     3  0.50
##  6  0.89954037     4     3  0.75
##  7 -0.90649045     6     0  0.00
##  8  0.04080467     5     1  0.20
##  9 -0.87067950     4     3  0.75
## 10 -0.84626183     4     1  0.25
## # ... with 20 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glm</span>(prob <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> tbProb, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">weights =</span> n) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</code></pre></div>
<pre><code>##          term  estimate std.error statistic     p.value
## 1 (Intercept) 0.1040801 0.1767316 0.5889159 0.555917662
## 2           x 0.9449956 0.3159439 2.9910234 0.002780442</code></pre>
<p>Notably, these fitted values are equivalent to what we would get if we were to transform each of our binomial responses into equivalent sets of Bernoulli trials. For example, the first observation in <code>tb</code> is a single success out of 5 attempts with a covariate of -0.011. Another way to think of this is five Bernoulli trials, one successful, four unsuccessful, all with a covariate value of -0.011.</p>
<p>For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tbTall</code></pre></div>
<pre><code>## # A tibble: 140 x 2
##              x     y
##          &lt;dbl&gt; &lt;dbl&gt;
##  1 -0.01132681     1
##  2 -0.01132681     0
##  3 -0.01132681     0
##  4 -0.01132681     0
##  5 -0.01132681     0
##  6 -0.26414193     1
##  7 -0.26414193     1
##  8 -0.26414193     0
##  9 -0.26414193     0
## 10 -0.81380816     0
## # ... with 130 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> tbTall, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</code></pre></div>
<pre><code>##          term  estimate std.error statistic     p.value
## 1 (Intercept) 0.1040801 0.1767316 0.5889159 0.555917669
## 2           x 0.9449956 0.3159439 2.9910233 0.002780443</code></pre>
<p>Note that while the degrees of freedom, information criteria, etc. are different, the coefficient estimates are the same, as are the standard errors for these coefficients.</p>
</div>
<div id="using-citools-for-binomial-regression" class="section level2">
<h2>Using <code>ciTools</code> for binomial regression</h2>
<p><code>ciTools</code> supports logistic regression with both Bernoulli and binomial response variables. For both types, <code>add_ci</code> has intuitive and expected functionality. It produces a point estimate and confidence intervals around the estimated probability of success. However, the other functions of <code>ciTools</code> (<code>add_pi</code>, <code>add_quantile</code>, and <code>add_probs</code>) produce different behaviors, because prediction intervals, quantiles, and probability values are not very useful for Bernoulli variables.</p>
<p>For example, consider prediction intervals. These are used to quantify the observation-to-observation variability and estimate its range. For a Bernoulli variable, only two values are possible, so this is not particularly meaningful – the prediction interval will always be <span class="math inline">\([0,1]\)</span>. Quantiles are similarly problematic. And probability estimates (that is, <span class="math inline">\(P(Y&gt;y|x)\)</span>) are equivalent to estimates of <span class="math inline">\(p\)</span> or <span class="math inline">\(1-p\)</span> . Thus, asking for any of these will produce either an error (in the case of <code>add_pi.glm(family = &quot;binomial)</code> or <code>add_quantiles(family = &quot;binomial)</code>) or a warning (in the case of <code>add_probs.glm(family = &quot;binomial&quot;)</code>).</p>
<p>For a binomial response, on the other hand, each of these functions produce meaningful output. Binomial response variables can take more than two values, making it sensible to consider prediction intervals, quantiles, or probabilities. For example, it may be interesting to consider the 90 percent quantile for a binomial regression:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">add_quantile</span>(tb, fit, <span class="dt">p =</span> <span class="fl">0.9</span>) </code></pre></div>
<pre><code>## Warning in add_quantile.glm(tb, fit, p = 0.9): Treating weights as
## indicating the number of trials for a binomial regression where the
## response is the proportion of successes</code></pre>
<pre><code>## Warning in add_quantile.glm(tb, fit, p = 0.9): The response variable is not
## continuous so Prediction Intervals are approximate</code></pre>
<pre><code>## Warning in sim_quantile_other(tb, fit, p, name, yhatName, nSims): For
## binomial models, add_quantile's column of fitted values reflect E(Y|X)
## rather than typical default for logistic regression, pHat</code></pre>
<pre><code>## # A tibble: 30 x 5
##              x     n     y     pred quantile0.9
##          &lt;dbl&gt; &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;       &lt;dbl&gt;
##  1 -0.01132681     5     1 2.616636           4
##  2 -0.26414193     4     2 1.854723           3
##  3 -0.81380816     4     0 1.358501           3
##  4  0.55575400     4     3 2.609291           4
##  5  0.65899013     6     3 4.044646           6
##  6  0.89954037     4     3 2.887789           4
##  7 -0.90649045     6     0 1.921596           4
##  8  0.04080467     5     1 2.677999           4
##  9 -0.87067950     4     3 1.310710           3
## 10 -0.84626183     4     1 1.331124           3
## # ... with 20 more rows</code></pre>
<p>There is a lot to unpack here, including three warning messages. Let’s consider the output first. Unlike when we use <code>add_ci.glm</code>, the <code>pred</code> column includes the predicted values <span class="math inline">\(E(Y|\boldsymbol{x})\)</span> rather than the estimated probability of success <span class="math inline">\(\hat{p}|\boldsymbol{x}\)</span>.</p>
<p>Next, there are three warnings. None of these indicate that anything has gone wrong. Rather, they are included to ensure that users understand the output they’re given. The first warning makes it clear to the user that the <code>weights</code> argument is assumed to indicate that they’re doing binomial rather than weighted Bernoulli regression. The second warning informs users that the estimated interval is approximate. This is because the current method used by <code>ciTools</code> for GLMs is based on simulation, and because <code>ciTools</code> forces quantile estimates to lie in the support set of the response distribution. The final warning points out that the <code>pred</code> column refers to the fitted values rather than estimated probability of success, which was mentioned in the previous paragraph.</p>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>Logistic regression can be used for both Bernoulli and Binomial response variables, and <code>glm</code> supports both. <code>ciTools</code> differentiates between the two based on whether the user has included a column in the <code>weights</code> argument. Aside from <code>add_ci</code>, none of the functions in <code>ciTools</code> produce useful information for Bernoulli response variables. For Binomial response variables, all of these functions produce useful information, though error messages are included to ensure that users understand the output presented.</p>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
